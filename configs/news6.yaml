---
model: Transformer
src_vocab: '../../parallel/news180w/zh.vocab'
dst_vocab: '../../parallel/news180w/en.vocab'
src_vocab_size: 9031
dst_vocab_size: 34218
hidden_units: 512
scale_embedding: True
num_shards: 1
tie_embedding_and_softmax: True
attention_dropout_rate: 0.0
residual_dropout_rate: 0.1
num_blocks: 6
num_heads: 8
ff_activation: 'relu'
model_dir: 'model-news6'
train:
  num_gpus: 8
  src_path: '../../parallel/news180w/zh.char.txt'
  dst_path: '../../parallel/news180w/en.bpe.txt'
  tokens_per_batch: 30000
  max_length: 125
  num_epochs: 100
  num_steps: 100000
  save_freq: 1000
  show_freq: 1
  summary_freq: 100
  grads_clip: 0
  optimizer: 'adam_decay'
  learning_rate: 1
  warmup_steps: 4000
  label_smoothing: 0.1
  toleration:
  eval_on_dev: True
dev:
  batch_size: 256
  src_path: '../../parallel/test/nist02.char.txt'
  ref_path: '../../parallel/test/nist02.ref'
  output_path: 'model-news6/nist02.output'

test:
  batch_size: 256
  max_target_length: 200
  lp_alpha: 0.6
  beam_size: 4
  num_gpus: 8

  set_nist02:
    src_path: '../../parallel/test/nist02.char.txt'
    ref_path: '../../parallel/test/nist02.ref'
    output_path: 'model-news6/nist02.output'
  set_nist03:
    src_path: '../../parallel/test/nist03.char.txt'
    ref_path: '../../parallel/test/nist03.ref'
    output_path: 'model-news6/nist03.output'
  set_nist04:
    src_path: '../../parallel/test/nist04.char.txt'
    ref_path: '../../parallel/test/nist04.ref'
    output_path: 'model-news6/nist04.output'
  set_nist05:
    src_path: '../../parallel/test/nist05.char.txt'
    ref_path: '../../parallel/test/nist05.ref'
    output_path: 'model-news6/nist05.output'

#  set_train:
#    src_path: '../../parallel/news180w/zh.char.txt'
#    output_path: 'model-news6/train.en'
